{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"Cyan\">Basic Perceptron</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "\n",
      "Physical devices available:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU')]\n",
      "\n",
      "GPU devices found:\n",
      "  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU')\n",
      "\n",
      "Matrix multiplication result: [[22. 28.]\n",
      " [49. 64.]]\n",
      "Device placement: /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Device placement policy:\n",
      "Soft device placement is enabled\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def check_tf_device():\n",
    "    # Check if TensorFlow can see any GPUs\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "    print(\"\\nPhysical devices available:\")\n",
    "    print(tf.config.list_physical_devices())\n",
    "    \n",
    "    # More detailed GPU information if available\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(\"\\nGPU devices found:\")\n",
    "        for gpu in gpus:\n",
    "            print(f\"  {gpu}\")\n",
    "        # Try to create a simple operation on GPU to verify it's working\n",
    "        with tf.device('/GPU:0'):\n",
    "            a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "            b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "            c = tf.matmul(a, b)\n",
    "            print(\"\\nMatrix multiplication result:\", c.numpy())\n",
    "            print(\"Device placement:\", c.device)\n",
    "    else:\n",
    "        print(\"\\nNo GPU devices found. TensorFlow is running on CPU.\")\n",
    "        \n",
    "    # Show current device placement policy\n",
    "    print(\"\\nDevice placement policy:\")\n",
    "    if tf.config.get_soft_device_placement():\n",
    "        print(\"Soft device placement is enabled\")\n",
    "    else:\n",
    "        print(\"Soft device placement is disabled\")\n",
    "\n",
    "check_tf_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TensorFlow GPU Troubleshooting ===\n",
      "\n",
      "TensorFlow version: 2.17.0\n",
      "\n",
      "CUDA_PATH: Not found in environment variables\n",
      "\n",
      "NVIDIA Driver Info:\n",
      "Sat Oct  5 10:56:11 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off | 00000000:14:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              37W / 250W |   2021MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-32GB           Off | 00000000:39:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              38W / 250W |    620MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE-32GB           Off | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              38W / 250W |    312MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-PCIE-40GB          Off | 00000000:88:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              61W / 250W |  38818MiB / 40960MiB |     14%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-PCIE-40GB          Off | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   50C    P0              66W / 250W |  14679MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-PCIE-40GB          Off | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              32W / 250W |    429MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-PCIE-40GB          Off | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              35W / 250W |    429MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      3400      G   /usr/libexec/Xorg                            63MiB |\n",
      "|    0   N/A  N/A     10998      G   /usr/bin/gnome-shell                         15MiB |\n",
      "|    0   N/A  N/A    851577      C   ...tech/2021/dibyo/DL/.venv/bin/python      308MiB |\n",
      "|    0   N/A  N/A   2692689      C   ...21b/miniconda3/envs/deep/bin/python     1630MiB |\n",
      "|    1   N/A  N/A    851577      C   ...tech/2021/dibyo/DL/.venv/bin/python      308MiB |\n",
      "|    1   N/A  N/A   1534541      C   ...niconda3/envs/tensorflow/bin/python      306MiB |\n",
      "|    2   N/A  N/A    851577      C   ...tech/2021/dibyo/DL/.venv/bin/python      308MiB |\n",
      "|    3   N/A  N/A    524583      C   python                                     2548MiB |\n",
      "|    3   N/A  N/A    531733      C   python                                     2548MiB |\n",
      "|    3   N/A  N/A    849562      C   python                                     2574MiB |\n",
      "|    3   N/A  N/A    851577      C   ...tech/2021/dibyo/DL/.venv/bin/python    23404MiB |\n",
      "|    3   N/A  N/A   3662424      C   python                                     2574MiB |\n",
      "|    3   N/A  N/A   3678604      C   python                                     2574MiB |\n",
      "|    3   N/A  N/A   3979261      C   python                                     2548MiB |\n",
      "|    4   N/A  N/A    851577      C   ...tech/2021/dibyo/DL/.venv/bin/python      416MiB |\n",
      "|    4   N/A  N/A   4154392      C   python3                                   14244MiB |\n",
      "|    5   N/A  N/A    851577      C   ...tech/2021/dibyo/DL/.venv/bin/python      416MiB |\n",
      "|    6   N/A  N/A    851577      C   ...tech/2021/dibyo/DL/.venv/bin/python      416MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "CUDA Version:\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.TC445_37.28845127_0\n",
      "\n",
      "\n",
      "TensorFlow GPU Devices:\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU')]\n",
      "\n",
      "Relevant Environment Variables:\n",
      "\n",
      "=== Troubleshooting Steps ===\n",
      "If no GPU is detected, check the following:\n",
      "1. Verify NVIDIA drivers are installed and up to date\n",
      "2. Ensure CUDA toolkit is installed and matches TensorFlow requirements\n",
      "3. Verify cuDNN is installed and matches CUDA version\n",
      "4. Check that your TensorFlow version supports your CUDA version\n",
      "5. Make sure your GPU is compatible with TensorFlow\n",
      "\n",
      "=== TensorFlow-CUDA Compatibility ===\n",
      "TensorFlow 2.10: CUDA 11.2, cuDNN 8.1\n",
      "TensorFlow 2.11-2.12: CUDA 11.8, cuDNN 8.6\n",
      "TensorFlow 2.13+: CUDA 11.8/12.0, cuDNN 8.6+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "def run_command(command):\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error executing {command}: {e.stderr}\"\n",
    "\n",
    "def check_gpu_prerequisites():\n",
    "    print(\"=== TensorFlow GPU Troubleshooting ===\\n\")\n",
    "    \n",
    "    # 1. Check TensorFlow version\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    \n",
    "    # 2. Check if CUDA is in PATH\n",
    "    cuda_path = os.environ.get('CUDA_PATH')\n",
    "    print(f\"\\nCUDA_PATH: {cuda_path if cuda_path else 'Not found in environment variables'}\")\n",
    "    \n",
    "    # 3. Check NVIDIA drivers\n",
    "    print(\"\\nNVIDIA Driver Info:\")\n",
    "    nvidia_smi = run_command('nvidia-smi')\n",
    "    print(nvidia_smi if nvidia_smi else \"nvidia-smi not found - drivers may not be installed\")\n",
    "    \n",
    "    # 4. Check CUDA version\n",
    "    print(\"\\nCUDA Version:\")\n",
    "    nvcc_version = run_command('nvcc --version')\n",
    "    print(nvcc_version if nvcc_version else \"nvcc not found - CUDA toolkit may not be installed\")\n",
    "    \n",
    "    # 5. Check cuDNN\n",
    "    cuda_path = os.environ.get('CUDA_PATH')\n",
    "    if cuda_path:\n",
    "        cudnn_path = os.path.join(cuda_path, 'include', 'cudnn.h')\n",
    "        if os.path.exists(cudnn_path):\n",
    "            print(\"\\ncuDNN found\")\n",
    "        else:\n",
    "            print(\"\\ncuDNN not found in expected location\")\n",
    "    \n",
    "    # 6. Check TensorFlow GPU devices\n",
    "    print(\"\\nTensorFlow GPU Devices:\")\n",
    "    print(tf.config.list_physical_devices('GPU'))\n",
    "    \n",
    "    # 7. Print CUDA device environment variables\n",
    "    print(\"\\nRelevant Environment Variables:\")\n",
    "    cuda_vars = {k: v for k, v in os.environ.items() if 'CUDA' in k}\n",
    "    for k, v in cuda_vars.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    # 8. Provide troubleshooting advice\n",
    "    print(\"\\n=== Troubleshooting Steps ===\")\n",
    "    print(\"If no GPU is detected, check the following:\")\n",
    "    print(\"1. Verify NVIDIA drivers are installed and up to date\")\n",
    "    print(\"2. Ensure CUDA toolkit is installed and matches TensorFlow requirements\")\n",
    "    print(\"3. Verify cuDNN is installed and matches CUDA version\")\n",
    "    print(\"4. Check that your TensorFlow version supports your CUDA version\")\n",
    "    print(\"5. Make sure your GPU is compatible with TensorFlow\")\n",
    "    \n",
    "    # Print TensorFlow-CUDA compatibility information\n",
    "    print(\"\\n=== TensorFlow-CUDA Compatibility ===\")\n",
    "    print(\"TensorFlow 2.10: CUDA 11.2, cuDNN 8.1\")\n",
    "    print(\"TensorFlow 2.11-2.12: CUDA 11.8, cuDNN 8.6\")\n",
    "    print(\"TensorFlow 2.13+: CUDA 11.8/12.0, cuDNN 8.6+\")\n",
    "\n",
    "\n",
    "check_gpu_prerequisites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#basic structure of a perceptron\n",
    "\n",
    "#input(s)_>corresponding weight(s) and bias>activation function_>output\n",
    "#the perceptron is a single layer neural network\n",
    "#it is the simplest form of a neural network\n",
    "#types of perceptrons\n",
    "#1. single layer perceptron\n",
    "#2. multi layer perceptron\n",
    "\n",
    "#types on the basis of input and output\n",
    "#1. single input single output\n",
    "#2. single input multiple output\n",
    "#3. multiple input single output\n",
    "#4. multiple input multiple output\n",
    "#5. binary input binary output\n",
    "#6. binary input multiple output\n",
    "#7. multiple input binary output\n",
    "\n",
    "#weights and bias are the parameters that the model learns\n",
    "x=0.0\n",
    "#four types of activation functions\n",
    "#2. sigmoid function\n",
    "print(tf.math.sigmoid(x))\n",
    "#3. rectified linear unit (ReLU)\n",
    "print(tf.nn.relu(x))\n",
    "#4. hyperbolic tangent function (tanh)\n",
    "print(tf.math.tanh(x))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
