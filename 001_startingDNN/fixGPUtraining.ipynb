{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"Cyan\">Basic Perceptron</font> after setting up some shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-06 09:50:21.932490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-06 09:50:21.990613: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-06 09:50:22.012761: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-06 09:50:22.075970: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-06 09:50:25.131051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "\n",
      "Physical devices available:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU')]\n",
      "\n",
      "GPU devices found:\n",
      "  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-06 09:50:32.106890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 858 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:88:00.0, compute capability: 8.0\n",
      "2024-10-06 09:50:32.150138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 23703 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:89:00.0, compute capability: 8.0\n",
      "2024-10-06 09:50:32.184375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 37953 MB memory:  -> device: 2, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:b1:00.0, compute capability: 8.0\n",
      "2024-10-06 09:50:32.212378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 37953 MB memory:  -> device: 3, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:b2:00.0, compute capability: 8.0\n",
      "2024-10-06 09:50:32.247230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 29123 MB memory:  -> device: 4, name: Tesla V100-PCIE-32GB, pci bus id: 0000:14:00.0, compute capability: 7.0\n",
      "2024-10-06 09:50:32.281293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30525 MB memory:  -> device: 5, name: Tesla V100-PCIE-32GB, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-10-06 09:50:32.315207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30833 MB memory:  -> device: 6, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix multiplication result: [[22. 28.]\n",
      " [49. 64.]]\n",
      "Device placement: /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Device placement policy:\n",
      "Soft device placement is enabled\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def check_tf_device():\n",
    "    # Check if TensorFlow can see any GPUs\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "    print(\"\\nPhysical devices available:\")\n",
    "    print(tf.config.list_physical_devices())\n",
    "    \n",
    "    # More detailed GPU information if available\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(\"\\nGPU devices found:\")\n",
    "        for gpu in gpus:\n",
    "            print(f\"  {gpu}\")\n",
    "        # Try to create a simple operation on GPU to verify it's working\n",
    "        with tf.device('/GPU:0'):\n",
    "            a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "            b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "            c = tf.matmul(a, b)\n",
    "            print(\"\\nMatrix multiplication result:\", c.numpy())\n",
    "            print(\"Device placement:\", c.device)\n",
    "    else:\n",
    "        print(\"\\nNo GPU devices found. TensorFlow is running on CPU.\")\n",
    "        \n",
    "    # Show current device placement policy\n",
    "    print(\"\\nDevice placement policy:\")\n",
    "    if tf.config.get_soft_device_placement():\n",
    "        print(\"Soft device placement is enabled\")\n",
    "    else:\n",
    "        print(\"Soft device placement is disabled\")\n",
    "\n",
    "check_tf_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
      "Requirement already satisfied: namex in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pip in /home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages (24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TensorFlow GPU Troubleshooting ===\n",
      "\n",
      "TensorFlow version: 2.17.0\n",
      "\n",
      "CUDA_PATH: Not found in environment variables\n",
      "\n",
      "NVIDIA Driver Info:\n",
      "Sat Oct  5 21:25:58 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off | 00000000:14:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              37W / 250W |   2021MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-32GB           Off | 00000000:39:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              37W / 250W |    620MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE-32GB           Off | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              37W / 250W |    312MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-PCIE-40GB          Off | 00000000:88:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              34W / 250W |  38818MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-PCIE-40GB          Off | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   57C    P0             165W / 250W |  14679MiB / 40960MiB |     23%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-PCIE-40GB          Off | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              32W / 250W |    429MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-PCIE-40GB          Off | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              34W / 250W |    429MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      3400      G   /usr/libexec/Xorg                            63MiB |\n",
      "|    0   N/A  N/A     10998      G   /usr/bin/gnome-shell                         15MiB |\n",
      "|    0   N/A  N/A   1017425      C   ...tech/2021/dibyo/DL/.venv/bin/python      308MiB |\n",
      "|    0   N/A  N/A   2692689      C   ...21b/miniconda3/envs/deep/bin/python     1630MiB |\n",
      "|    1   N/A  N/A   1017425      C   ...tech/2021/dibyo/DL/.venv/bin/python      308MiB |\n",
      "|    1   N/A  N/A   1534541      C   ...niconda3/envs/tensorflow/bin/python      306MiB |\n",
      "|    2   N/A  N/A   1017425      C   ...tech/2021/dibyo/DL/.venv/bin/python      308MiB |\n",
      "|    3   N/A  N/A    870433      C   python                                      618MiB |\n",
      "|    3   N/A  N/A    970677      C   ...ta22b/miniconda3/envs/dg/bin/python     1156MiB |\n",
      "|    3   N/A  N/A   1017425      C   ...tech/2021/dibyo/DL/.venv/bin/python    34464MiB |\n",
      "|    3   N/A  N/A   3979261      C   python                                     2548MiB |\n",
      "|    4   N/A  N/A   1017425      C   ...tech/2021/dibyo/DL/.venv/bin/python      416MiB |\n",
      "|    4   N/A  N/A   4154392      C   python3                                   14244MiB |\n",
      "|    5   N/A  N/A   1017425      C   ...tech/2021/dibyo/DL/.venv/bin/python      416MiB |\n",
      "|    6   N/A  N/A   1017425      C   ...tech/2021/dibyo/DL/.venv/bin/python      416MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "CUDA Version:\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.TC445_37.28845127_0\n",
      "\n",
      "\n",
      "TensorFlow GPU Devices:\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU')]\n",
      "\n",
      "Relevant Environment Variables:\n",
      "\n",
      "=== Troubleshooting Steps ===\n",
      "If no GPU is detected, check the following:\n",
      "1. Verify NVIDIA drivers are installed and up to date\n",
      "2. Ensure CUDA toolkit is installed and matches TensorFlow requirements\n",
      "3. Verify cuDNN is installed and matches CUDA version\n",
      "4. Check that your TensorFlow version supports your CUDA version\n",
      "5. Make sure your GPU is compatible with TensorFlow\n",
      "\n",
      "=== TensorFlow-CUDA Compatibility ===\n",
      "TensorFlow 2.10: CUDA 11.2, cuDNN 8.1\n",
      "TensorFlow 2.11-2.12: CUDA 11.8, cuDNN 8.6\n",
      "TensorFlow 2.13+: CUDA 11.8/12.0, cuDNN 8.6+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "def run_command(command):\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error executing {command}: {e.stderr}\"\n",
    "\n",
    "def check_gpu_prerequisites():\n",
    "    print(\"=== TensorFlow GPU Troubleshooting ===\\n\")\n",
    "    \n",
    "    # 1. Check TensorFlow version\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    \n",
    "    # 2. Check if CUDA is in PATH\n",
    "    cuda_path = os.environ.get('CUDA_PATH')\n",
    "    print(f\"\\nCUDA_PATH: {cuda_path if cuda_path else 'Not found in environment variables'}\")\n",
    "    \n",
    "    # 3. Check NVIDIA drivers\n",
    "    print(\"\\nNVIDIA Driver Info:\")\n",
    "    nvidia_smi = run_command('nvidia-smi')\n",
    "    print(nvidia_smi if nvidia_smi else \"nvidia-smi not found - drivers may not be installed\")\n",
    "    \n",
    "    # 4. Check CUDA version\n",
    "    print(\"\\nCUDA Version:\")\n",
    "    nvcc_version = run_command('nvcc --version')\n",
    "    print(nvcc_version if nvcc_version else \"nvcc not found - CUDA toolkit may not be installed\")\n",
    "    \n",
    "    # 5. Check cuDNN\n",
    "    cuda_path = os.environ.get('CUDA_PATH')\n",
    "    if cuda_path:\n",
    "        cudnn_path = os.path.join(cuda_path, 'include', 'cudnn.h')\n",
    "        if os.path.exists(cudnn_path):\n",
    "            print(\"\\ncuDNN found\")\n",
    "        else:\n",
    "            print(\"\\ncuDNN not found in expected location\")\n",
    "    \n",
    "    # 6. Check TensorFlow GPU devices\n",
    "    print(\"\\nTensorFlow GPU Devices:\")\n",
    "    print(tf.config.list_physical_devices('GPU'))\n",
    "    \n",
    "    # 7. Print CUDA device environment variables\n",
    "    print(\"\\nRelevant Environment Variables:\")\n",
    "    cuda_vars = {k: v for k, v in os.environ.items() if 'CUDA' in k}\n",
    "    for k, v in cuda_vars.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    # 8. Provide troubleshooting advice\n",
    "    print(\"\\n=== Troubleshooting Steps ===\")\n",
    "    print(\"If no GPU is detected, check the following:\")\n",
    "    print(\"1. Verify NVIDIA drivers are installed and up to date\")\n",
    "    print(\"2. Ensure CUDA toolkit is installed and matches TensorFlow requirements\")\n",
    "    print(\"3. Verify cuDNN is installed and matches CUDA version\")\n",
    "    print(\"4. Check that your TensorFlow version supports your CUDA version\")\n",
    "    print(\"5. Make sure your GPU is compatible with TensorFlow\")\n",
    "    \n",
    "    # Print TensorFlow-CUDA compatibility information\n",
    "    print(\"\\n=== TensorFlow-CUDA Compatibility ===\")\n",
    "    print(\"TensorFlow 2.10: CUDA 11.2, cuDNN 8.1\")\n",
    "    print(\"TensorFlow 2.11-2.12: CUDA 11.8, cuDNN 8.6\")\n",
    "    print(\"TensorFlow 2.13+: CUDA 11.8/12.0, cuDNN 8.6+\")\n",
    "\n",
    "\n",
    "check_gpu_prerequisites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-05 21:26:02.458271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-05 21:26:02.490558: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-05 21:26:02.500699: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-05 21:26:02.525788: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-05 21:26:05.466488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-10-05 21:26:12.604370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 875 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:88:00.0, compute capability: 8.0\n",
      "2024-10-05 21:26:12.668654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 23703 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:89:00.0, compute capability: 8.0\n",
      "2024-10-05 21:26:12.712370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 37953 MB memory:  -> device: 2, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:b1:00.0, compute capability: 8.0\n",
      "2024-10-05 21:26:12.740563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 37953 MB memory:  -> device: 3, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:b2:00.0, compute capability: 8.0\n",
      "2024-10-05 21:26:12.779183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 29123 MB memory:  -> device: 4, name: Tesla V100-PCIE-32GB, pci bus id: 0000:14:00.0, compute capability: 7.0\n",
      "2024-10-05 21:26:12.804269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30525 MB memory:  -> device: 5, name: Tesla V100-PCIE-32GB, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-10-05 21:26:12.838131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30833 MB memory:  -> device: 6, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n",
      "tf.Tensor(-222.74573, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n",
      "Tensor(\"Sum:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Prevent duplicate registrations without disabling optimizations\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# Import and configure TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Disable eager execution to potentially improve performance\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Configure TensorFlow to use memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Optional: Set up mixed precision for potential performance boost\n",
    "try:\n",
    "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "    tf.keras.mixed_precision.set_global_policy(policy)\n",
    "except:\n",
    "    print(\"Mixed precision not available, using default precision\")\n",
    "\n",
    "# Your TensorFlow code here\n",
    "# For example:\n",
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/home/mtech/2021/dibyo/.anaconda/envs/CPU2/lib/python3.12/lib-dynload/../../libcublas.so: undefined symbol: cublasLtHSHMatmulAlgoInit, version libcublasLt.so.11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Call the function to force registration\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mforce_cuda_registration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Your TensorFlow code here\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# For example:\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39mreduce_sum(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1000\u001b[39m])))\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mforce_cuda_registration\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforce_cuda_registration\u001b[39m():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Force load CUDA libraries\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mCDLL(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart.so\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibcublas.so\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mCDLL(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcufft.so\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mCDLL(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcurand.so\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.anaconda/envs/CPU2/lib/python3.12/ctypes/__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /home/mtech/2021/dibyo/.anaconda/envs/CPU2/lib/python3.12/lib-dynload/../../libcublas.so: undefined symbol: cublasLtHSHMatmulAlgoInit, version libcublasLt.so.11"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import ctypes\n",
    "import tensorflow as tf\n",
    "\n",
    "def force_cuda_registration():\n",
    "    # Force load CUDA libraries\n",
    "    ctypes.CDLL(\"libcudart.so\")\n",
    "    ctypes.CDLL(\"libcublas.so\")\n",
    "    ctypes.CDLL(\"libcufft.so\")\n",
    "    ctypes.CDLL(\"libcurand.so\")\n",
    "    ctypes.CDLL(\"libcusolver.so\")\n",
    "    ctypes.CDLL(\"libcusparse.so\")\n",
    "    ctypes.CDLL(\"libcudnn.so\")\n",
    "\n",
    "    # Set environment variables to force registration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    os.environ['TF_FORCE_CUDA_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "    # Clear any existing GPU devices\n",
    "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "\n",
    "    # Reinitialize TensorFlow's GPU configuration\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "# Call the function to force registration\n",
    "force_cuda_registration()\n",
    "\n",
    "# Your TensorFlow code here\n",
    "# For example:\n",
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available? [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Is GPU available?\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtech/2021/dibyo/.anaconda/envs/CPU2/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728188492.352739 1132287 service.cc:146] XLA service 0x7f81400038e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728188492.352767 1132287 service.cc:154]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "I0000 00:00:1728188492.352771 1132287 service.cc:154]   StreamExecutor device (1): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "I0000 00:00:1728188492.352777 1132287 service.cc:154]   StreamExecutor device (2): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "I0000 00:00:1728188492.352782 1132287 service.cc:154]   StreamExecutor device (3): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "I0000 00:00:1728188492.352787 1132287 service.cc:154]   StreamExecutor device (4): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1728188492.352793 1132287 service.cc:154]   StreamExecutor device (5): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1728188492.352798 1132287 service.cc:154]   StreamExecutor device (6): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2024-10-06 09:51:32.513658: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-06 09:51:32.966117: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   3/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16\u001b[0m 41ms/step - accuracy: 0.0625 - loss: 2.3082  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728188499.455862 1132287 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 37ms/step - accuracy: 0.9000 - loss: 0.3226 - val_accuracy: 0.9870 - val_loss: 0.0405\n",
      "Epoch 2/2\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 31ms/step - accuracy: 0.9859 - loss: 0.0468 - val_accuracy: 0.9831 - val_loss: 0.0509\n",
      "313/313 - 5s - 15ms/step - accuracy: 0.9831 - loss: 0.0509\n",
      "\n",
      "Test accuracy: 0.9830999970436096\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Reshape images to include channel dimension\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=2, \n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 21:45:37.833633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-05 21:45:37.918288: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-05 21:45:37.929373: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-05 21:45:37.989846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-05 21:45:41.020099: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-05 21:45:51.535492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 849 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:88:00.0, compute capability: 8.0\n",
      "2024-10-05 21:45:51.563585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 23703 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:89:00.0, compute capability: 8.0\n",
      "2024-10-05 21:45:51.590331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 37953 MB memory:  -> device: 2, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:b1:00.0, compute capability: 8.0\n",
      "2024-10-05 21:45:51.617326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 37953 MB memory:  -> device: 3, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:b2:00.0, compute capability: 8.0\n",
      "2024-10-05 21:45:51.642156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 29123 MB memory:  -> device: 4, name: Tesla V100-PCIE-32GB, pci bus id: 0000:14:00.0, compute capability: 7.0\n",
      "2024-10-05 21:45:51.667140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30525 MB memory:  -> device: 5, name: Tesla V100-PCIE-32GB, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-10-05 21:45:51.710125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30833 MB memory:  -> device: 6, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n",
      "/home/mtech/2021/dibyo/DL/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728144963.171801 1025020 service.cc:146] XLA service 0x7f8378010a20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728144963.171847 1025020 service.cc:154]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "I0000 00:00:1728144963.171851 1025020 service.cc:154]   StreamExecutor device (1): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "I0000 00:00:1728144963.171857 1025020 service.cc:154]   StreamExecutor device (2): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "I0000 00:00:1728144963.171861 1025020 service.cc:154]   StreamExecutor device (3): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "I0000 00:00:1728144963.171866 1025020 service.cc:154]   StreamExecutor device (4): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1728144963.171871 1025020 service.cc:154]   StreamExecutor device (5): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1728144963.171877 1025020 service.cc:154]   StreamExecutor device (6): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2024-10-05 21:46:03.427451: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-05 21:46:04.563751: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/938\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 91ms/step - accuracy: 0.1758 - loss: 3.1798  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728144978.206789 1025020 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 94ms/step - accuracy: 0.8257 - loss: 0.5591 - val_accuracy: 0.9834 - val_loss: 0.0538\n",
      "Epoch 2/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 71ms/step - accuracy: 0.9651 - loss: 0.1175 - val_accuracy: 0.9769 - val_loss: 0.0795\n",
      "Epoch 3/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 76ms/step - accuracy: 0.9752 - loss: 0.0907 - val_accuracy: 0.9813 - val_loss: 0.0690\n",
      "Epoch 4/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 73ms/step - accuracy: 0.9787 - loss: 0.0753 - val_accuracy: 0.9763 - val_loss: 0.0773\n",
      "Epoch 5/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 73ms/step - accuracy: 0.9812 - loss: 0.0694 - val_accuracy: 0.9920 - val_loss: 0.0261\n",
      "Epoch 6/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 73ms/step - accuracy: 0.9811 - loss: 0.0693 - val_accuracy: 0.9909 - val_loss: 0.0315\n",
      "Epoch 7/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 73ms/step - accuracy: 0.9837 - loss: 0.0599 - val_accuracy: 0.9909 - val_loss: 0.0283\n",
      "Epoch 8/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 75ms/step - accuracy: 0.9845 - loss: 0.0526 - val_accuracy: 0.9932 - val_loss: 0.0255\n",
      "Epoch 9/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 71ms/step - accuracy: 0.9868 - loss: 0.0503 - val_accuracy: 0.9903 - val_loss: 0.0319\n",
      "Epoch 10/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9860 - loss: 0.0517 - val_accuracy: 0.9922 - val_loss: 0.0279\n",
      "Epoch 11/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 53ms/step - accuracy: 0.9874 - loss: 0.0478 - val_accuracy: 0.9907 - val_loss: 0.0308\n",
      "Epoch 12/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 68ms/step - accuracy: 0.9876 - loss: 0.0447 - val_accuracy: 0.9943 - val_loss: 0.0194\n",
      "Epoch 13/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 68ms/step - accuracy: 0.9878 - loss: 0.0443 - val_accuracy: 0.9930 - val_loss: 0.0222\n",
      "Epoch 14/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 68ms/step - accuracy: 0.9883 - loss: 0.0425 - val_accuracy: 0.9901 - val_loss: 0.0372\n",
      "Epoch 15/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 70ms/step - accuracy: 0.9895 - loss: 0.0373 - val_accuracy: 0.9942 - val_loss: 0.0228\n",
      "313/313 - 5s - 15ms/step - accuracy: 0.9942 - loss: 0.0228\n",
      "\n",
      "Test accuracy: 0.9941999912261963\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Reshape images to include channel dimension\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "datagen.fit(train_images)\n",
    "\n",
    "# Define the CNN model with additional layers and batch normalization\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Adding dropout for regularization\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with data augmentation\n",
    "history = model.fit(datagen.flow(train_images, train_labels, batch_size=64),\n",
    "                    epochs=15,  # Increased number of epochs\n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "else:\n",
    "    print(\"No GPU found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPU2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
